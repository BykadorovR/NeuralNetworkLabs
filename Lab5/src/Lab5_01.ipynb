{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(777)\n",
    "goal_num_classes = 101\n",
    "epochs = 35\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import applications\n",
    "import copy\n",
    "import time\n",
    "\n",
    "batch_size = 16\n",
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAL DATA READED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###Read Goal Data Set\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image\n",
    "ImagesPath=\"D:\\\\SomeData\\\\Caltech101\\\\Images\\\\\"\n",
    "classes = [f for f in listdir(ImagesPath)]\n",
    "train_volume=0.7\n",
    "size = 128,128\n",
    "src_num_classes = 101\n",
    "goal_x_train=[]\n",
    "goal_x_test=[]\n",
    "goal_y_train=[]\n",
    "goal_y_test=[]\n",
    "\n",
    "for i in range(0,len(classes)):\n",
    "    images=listdir(ImagesPath+classes[i])\n",
    "    for j in range(0,(int)(len(images)*train_volume)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        goal_x_train.append(data)\n",
    "        goal_y_train.append(np.uint8(i))\n",
    "    for j in range((int)(len(images)*train_volume),len(images)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        goal_x_test.append(data)\n",
    "        goal_y_test.append(np.uint8(i))\n",
    "goal_x_test=np.array(goal_x_test)\n",
    "goal_x_train=np.array(goal_x_train)\n",
    "goal_y_train=to_categorical(goal_y_train, num_classes=src_num_classes)\n",
    "goal_y_test=to_categorical(goal_y_test, num_classes=src_num_classes)\n",
    "print (\"GOAL DATA READED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 314,469\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 20s - loss: 3.3391 - acc: 0.3040 - val_loss: 2.7022 - val_acc: 0.4119\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 18s - loss: 2.2724 - acc: 0.4985 - val_loss: 2.0409 - val_acc: 0.5436\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 18s - loss: 1.7588 - acc: 0.5919 - val_loss: 1.6955 - val_acc: 0.5907\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 18s - loss: 1.4410 - acc: 0.6547 - val_loss: 1.4997 - val_acc: 0.6315\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 18s - loss: 1.2424 - acc: 0.6958 - val_loss: 1.3411 - val_acc: 0.6707\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 17s - loss: 1.1068 - acc: 0.7254 - val_loss: 1.2467 - val_acc: 0.6816\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 17s - loss: 1.0017 - acc: 0.7405 - val_loss: 1.1845 - val_acc: 0.6952\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.9185 - acc: 0.7622 - val_loss: 1.1466 - val_acc: 0.7088\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.8529 - acc: 0.7733 - val_loss: 1.0942 - val_acc: 0.7209\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.7956 - acc: 0.7902 - val_loss: 1.0537 - val_acc: 0.7171\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.7458 - acc: 0.8000 - val_loss: 1.0534 - val_acc: 0.7318\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.6969 - acc: 0.8135 - val_loss: 1.0019 - val_acc: 0.7397\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.6612 - acc: 0.8214 - val_loss: 0.9832 - val_acc: 0.7356\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.6303 - acc: 0.8332 - val_loss: 0.9929 - val_acc: 0.7288\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.6080 - acc: 0.8346 - val_loss: 0.9866 - val_acc: 0.7367\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.5719 - acc: 0.8453 - val_loss: 0.9383 - val_acc: 0.7435\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.5420 - acc: 0.8518 - val_loss: 0.9799 - val_acc: 0.7375\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.5204 - acc: 0.8576 - val_loss: 0.9679 - val_acc: 0.7416\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.4944 - acc: 0.8654 - val_loss: 0.9508 - val_acc: 0.7499\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.4757 - acc: 0.8704 - val_loss: 0.9021 - val_acc: 0.7624\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.4561 - acc: 0.8752 - val_loss: 0.9248 - val_acc: 0.7571\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.4391 - acc: 0.8777 - val_loss: 0.9094 - val_acc: 0.7612\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.4236 - acc: 0.8842 - val_loss: 0.8736 - val_acc: 0.7642\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.4058 - acc: 0.8921 - val_loss: 0.9091 - val_acc: 0.7571\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.3927 - acc: 0.8901 - val_loss: 0.8838 - val_acc: 0.7680\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.3794 - acc: 0.8974 - val_loss: 0.9258 - val_acc: 0.7616\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.3616 - acc: 0.9016 - val_loss: 0.9135 - val_acc: 0.7567\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.3532 - acc: 0.9028 - val_loss: 0.9530 - val_acc: 0.7548\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.3373 - acc: 0.9111 - val_loss: 0.8977 - val_acc: 0.7627\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.3297 - acc: 0.9082 - val_loss: 0.8712 - val_acc: 0.7782\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.3112 - acc: 0.9164 - val_loss: 0.9295 - val_acc: 0.7608\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.2990 - acc: 0.9180 - val_loss: 0.8938 - val_acc: 0.7710\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 17s - loss: 0.2859 - acc: 0.9228 - val_loss: 0.9408 - val_acc: 0.7593\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.2824 - acc: 0.9198 - val_loss: 0.9004 - val_acc: 0.7680\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 18s - loss: 0.2711 - acc: 0.9263 - val_loss: 0.8908 - val_acc: 0.7703\n",
      "Time = 636.3881914615631\n"
     ]
    }
   ],
   "source": [
    "###1th Experiment: frozen kernel\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#load pre-trein weights\n",
    "model.load_weights(\"D:\\\\SomeData\\\\KerasWeights\\\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")# WA for avoid directly download issue\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "#froze kernel's weights\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 15,029,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 51s - loss: 2.7100 - acc: 0.4094 - val_loss: 2.1359 - val_acc: 0.4881\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 44s - loss: 1.3759 - acc: 0.6500 - val_loss: 1.3040 - val_acc: 0.6688\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.8629 - acc: 0.7682 - val_loss: 0.9818 - val_acc: 0.7427\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.5461 - acc: 0.8480 - val_loss: 1.0542 - val_acc: 0.7665\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.3898 - acc: 0.8911 - val_loss: 0.8066 - val_acc: 0.7888\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.2693 - acc: 0.9203 - val_loss: 0.7954 - val_acc: 0.8065\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.2414 - acc: 0.9281 - val_loss: 0.8053 - val_acc: 0.8050\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1807 - acc: 0.9462 - val_loss: 0.6424 - val_acc: 0.8340\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1631 - acc: 0.9577 - val_loss: 0.7115 - val_acc: 0.8374\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1283 - acc: 0.9638 - val_loss: 0.6901 - val_acc: 0.8280\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1062 - acc: 0.9713 - val_loss: 0.8100 - val_acc: 0.8171\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.0831 - acc: 0.9761 - val_loss: 0.6779 - val_acc: 0.8589\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.0372 - acc: 0.9894 - val_loss: 0.9551 - val_acc: 0.8231\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.0629 - acc: 0.9831 - val_loss: 0.6293 - val_acc: 0.8582\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.0515 - acc: 0.9876 - val_loss: 1.0050 - val_acc: 0.7989\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.0565 - acc: 0.9861 - val_loss: 0.5883 - val_acc: 0.8668\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.0256 - acc: 0.9935 - val_loss: 0.5641 - val_acc: 0.8823\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.0030 - acc: 0.9993 - val_loss: 0.5357 - val_acc: 0.8902\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 45s - loss: 6.6815e-04 - acc: 0.9998 - val_loss: 0.5378 - val_acc: 0.8902\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 45s - loss: 5.1688e-04 - acc: 0.9998 - val_loss: 0.5514 - val_acc: 0.8887\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 45s - loss: 7.5784e-04 - acc: 0.9997 - val_loss: 0.5473 - val_acc: 0.8902\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 45s - loss: 4.5220e-04 - acc: 0.9998 - val_loss: 0.5508 - val_acc: 0.8921\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 44s - loss: 4.3780e-04 - acc: 0.9998 - val_loss: 0.5553 - val_acc: 0.8891\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 45s - loss: 4.3748e-04 - acc: 0.9997 - val_loss: 0.5598 - val_acc: 0.8906\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.1875e-04 - acc: 0.9998 - val_loss: 0.5676 - val_acc: 0.8917\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 45s - loss: 4.0517e-04 - acc: 0.9998 - val_loss: 0.5671 - val_acc: 0.8921\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.5469e-04 - acc: 0.9998 - val_loss: 0.5716 - val_acc: 0.8917\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.6617e-04 - acc: 0.9997 - val_loss: 0.5740 - val_acc: 0.8917\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 44s - loss: 3.8878e-04 - acc: 0.9997 - val_loss: 0.5764 - val_acc: 0.8921\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.9110e-04 - acc: 0.9997 - val_loss: 0.5774 - val_acc: 0.8914\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.6087e-04 - acc: 0.9998 - val_loss: 0.5794 - val_acc: 0.8921\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 45s - loss: 2.5958e-04 - acc: 0.9998 - val_loss: 0.5856 - val_acc: 0.8925\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.8208e-04 - acc: 0.9998 - val_loss: 0.5846 - val_acc: 0.8917\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.5257e-04 - acc: 0.9998 - val_loss: 0.5853 - val_acc: 0.8921\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 44s - loss: 3.3968e-04 - acc: 0.9997 - val_loss: 0.5898 - val_acc: 0.8910\n",
      "Time = 1587.8323018550873\n"
     ]
    }
   ],
   "source": [
    "###2th Experiment: trainable kernel\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#load pre-trein weights\n",
    "model.load_weights(\"D:\\\\SomeData\\\\KerasWeights\\\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")# WA for avoid directly download issue\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 15,029,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 49s - loss: 4.2897 - acc: 0.0924 - val_loss: 4.2066 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 44s - loss: 4.1992 - acc: 0.0943 - val_loss: 4.2016 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 45s - loss: 4.1940 - acc: 0.0943 - val_loss: 4.2035 - val_acc: 0.0905\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 45s - loss: 4.1904 - acc: 0.0914 - val_loss: 4.1866 - val_acc: 0.0905\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 45s - loss: 4.0836 - acc: 0.1127 - val_loss: 3.9635 - val_acc: 0.1837\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.6857 - acc: 0.2191 - val_loss: 3.3937 - val_acc: 0.2780\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.3643 - acc: 0.2730 - val_loss: 3.2003 - val_acc: 0.3074\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 45s - loss: 3.1196 - acc: 0.3231 - val_loss: 3.0497 - val_acc: 0.3463\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 45s - loss: 2.8551 - acc: 0.3716 - val_loss: 2.7815 - val_acc: 0.3968\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 45s - loss: 2.5695 - acc: 0.4200 - val_loss: 2.6377 - val_acc: 0.4357\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 45s - loss: 2.2857 - acc: 0.4698 - val_loss: 2.6126 - val_acc: 0.4236\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 45s - loss: 2.0283 - acc: 0.5221 - val_loss: 2.5098 - val_acc: 0.4413\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 45s - loss: 1.7759 - acc: 0.5695 - val_loss: 2.3429 - val_acc: 0.4821\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 45s - loss: 1.5337 - acc: 0.6221 - val_loss: 2.3110 - val_acc: 0.4968\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 45s - loss: 1.3141 - acc: 0.6673 - val_loss: 2.2935 - val_acc: 0.5047\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 45s - loss: 1.0539 - acc: 0.7265 - val_loss: 2.4669 - val_acc: 0.5096\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 44s - loss: 0.8910 - acc: 0.7645 - val_loss: 2.7631 - val_acc: 0.5179\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.6964 - acc: 0.8158 - val_loss: 2.5733 - val_acc: 0.5247\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 44s - loss: 0.6311 - acc: 0.8281 - val_loss: 2.6817 - val_acc: 0.5213\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 44s - loss: 0.5477 - acc: 0.8581 - val_loss: 3.3828 - val_acc: 0.5126\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 44s - loss: 0.4496 - acc: 0.8820 - val_loss: 2.6283 - val_acc: 0.5273\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.3650 - acc: 0.9049 - val_loss: 3.4051 - val_acc: 0.5130\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 44s - loss: 0.3215 - acc: 0.9235 - val_loss: 3.1996 - val_acc: 0.5258\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.2486 - acc: 0.9359 - val_loss: 3.9074 - val_acc: 0.5368\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.2093 - acc: 0.9461 - val_loss: 4.0606 - val_acc: 0.5006\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 44s - loss: 0.2498 - acc: 0.9358 - val_loss: 4.0121 - val_acc: 0.5368\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1788 - acc: 0.9552 - val_loss: 3.1628 - val_acc: 0.5439\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1628 - acc: 0.9587 - val_loss: 4.1298 - val_acc: 0.5175\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 44s - loss: 0.1876 - acc: 0.9542 - val_loss: 3.2833 - val_acc: 0.5375\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1271 - acc: 0.9695 - val_loss: 2.9099 - val_acc: 0.5462\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1012 - acc: 0.9759 - val_loss: 4.4392 - val_acc: 0.5387\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.1212 - acc: 0.9726 - val_loss: 4.0690 - val_acc: 0.5383\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 44s - loss: 0.0914 - acc: 0.9774 - val_loss: 3.0963 - val_acc: 0.5409\n",
      "Epoch 34/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 45s - loss: 0.1115 - acc: 0.9725 - val_loss: 3.5060 - val_acc: 0.5481\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 45s - loss: 0.0760 - acc: 0.9829 - val_loss: 4.8273 - val_acc: 0.4859\n",
      "Time = 1587.1510243415833\n"
     ]
    }
   ],
   "source": [
    "###3th Experiment: just VGG16 struct (don't load pre train weights)\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
