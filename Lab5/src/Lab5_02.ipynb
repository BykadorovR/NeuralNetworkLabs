{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(777)\n",
    "goal_num_classes = 101\n",
    "epochs = 35\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import applications\n",
    "import copy\n",
    "import time\n",
    "\n",
    "batch_size = 64\n",
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAL DATA READED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###Read Goal Data Set\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image\n",
    "ImagesPath=\"D:\\\\SomeData\\\\Caltech101\\\\Images\\\\\"\n",
    "classes = [f for f in listdir(ImagesPath)]\n",
    "train_volume=0.7\n",
    "size = 128,128\n",
    "src_num_classes = 101\n",
    "goal_x_train=[]\n",
    "goal_x_test=[]\n",
    "goal_y_train=[]\n",
    "goal_y_test=[]\n",
    "\n",
    "for i in range(0,len(classes)):\n",
    "    images=listdir(ImagesPath+classes[i])\n",
    "    for j in range(0,(int)(len(images)*train_volume)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        goal_x_train.append(data)\n",
    "        goal_y_train.append(np.uint8(i))\n",
    "    for j in range((int)(len(images)*train_volume),len(images)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        goal_x_test.append(data)\n",
    "        goal_y_test.append(np.uint8(i))\n",
    "goal_x_test=np.array(goal_x_test)\n",
    "goal_x_train=np.array(goal_x_train)\n",
    "goal_y_train=to_categorical(goal_y_train, num_classes=src_num_classes)\n",
    "goal_y_test=to_categorical(goal_y_test, num_classes=src_num_classes)\n",
    "print (\"GOAL DATA READED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 314,469\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 20s - loss: 3.9456 - acc: 0.1932 - val_loss: 3.5511 - val_acc: 0.2867\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.2869 - acc: 0.3102 - val_loss: 3.0786 - val_acc: 0.3372\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 14s - loss: 2.8881 - acc: 0.3835 - val_loss: 2.7817 - val_acc: 0.4032\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 2.5877 - acc: 0.4569 - val_loss: 2.5187 - val_acc: 0.4610\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 14s - loss: 2.3399 - acc: 0.5060 - val_loss: 2.3036 - val_acc: 0.5006\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 2.1341 - acc: 0.5417 - val_loss: 2.1347 - val_acc: 0.5526\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.9630 - acc: 0.5755 - val_loss: 1.9831 - val_acc: 0.5692\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 14s - loss: 1.8145 - acc: 0.6042 - val_loss: 1.8615 - val_acc: 0.5839\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.6944 - acc: 0.6318 - val_loss: 1.7585 - val_acc: 0.6020\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.5893 - acc: 0.6515 - val_loss: 1.6717 - val_acc: 0.6243\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.4952 - acc: 0.6709 - val_loss: 1.5939 - val_acc: 0.6375\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.4122 - acc: 0.6877 - val_loss: 1.5299 - val_acc: 0.6481\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.3474 - acc: 0.6970 - val_loss: 1.4816 - val_acc: 0.6484\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.2819 - acc: 0.7108 - val_loss: 1.4182 - val_acc: 0.6680\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.2230 - acc: 0.7209 - val_loss: 1.3749 - val_acc: 0.6748\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.1736 - acc: 0.7351 - val_loss: 1.3416 - val_acc: 0.6779\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.1308 - acc: 0.7398 - val_loss: 1.3126 - val_acc: 0.6790\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.0876 - acc: 0.7498 - val_loss: 1.2782 - val_acc: 0.6850\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.0523 - acc: 0.7511 - val_loss: 1.2410 - val_acc: 0.6922\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.0146 - acc: 0.7654 - val_loss: 1.2103 - val_acc: 0.7046\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.9862 - acc: 0.7727 - val_loss: 1.2023 - val_acc: 0.6967\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.9573 - acc: 0.7731 - val_loss: 1.1695 - val_acc: 0.7088\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.9264 - acc: 0.7796 - val_loss: 1.1579 - val_acc: 0.7144\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.9014 - acc: 0.7863 - val_loss: 1.1496 - val_acc: 0.7061\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.8792 - acc: 0.7902 - val_loss: 1.1159 - val_acc: 0.7160\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.8565 - acc: 0.7939 - val_loss: 1.0963 - val_acc: 0.7239\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.8303 - acc: 0.8000 - val_loss: 1.0900 - val_acc: 0.7209\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.8144 - acc: 0.8053 - val_loss: 1.0871 - val_acc: 0.7114\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 14s - loss: 0.7959 - acc: 0.8077 - val_loss: 1.0597 - val_acc: 0.7284\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.7759 - acc: 0.8131 - val_loss: 1.0609 - val_acc: 0.7201\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.7632 - acc: 0.8158 - val_loss: 1.0496 - val_acc: 0.7182\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.7462 - acc: 0.8153 - val_loss: 1.0376 - val_acc: 0.7276\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.7289 - acc: 0.8281 - val_loss: 1.0191 - val_acc: 0.7409\n",
      "Epoch 34/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 15s - loss: 0.7142 - acc: 0.8238 - val_loss: 1.0155 - val_acc: 0.7329\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.7020 - acc: 0.8311 - val_loss: 1.0278 - val_acc: 0.7269\n",
      "Time = 534.6578698158264\n"
     ]
    }
   ],
   "source": [
    "###1th Experiment: frozen kernel\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#load pre-trein weights\n",
    "model.load_weights(\"D:\\\\SomeData\\\\KerasWeights\\\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")# WA for avoid directly download issue\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "#froze kernel's weights\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 15,029,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 39s - loss: 2.6813 - acc: 0.4233 - val_loss: 2.0251 - val_acc: 0.5183\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 37s - loss: 1.1117 - acc: 0.7220 - val_loss: 1.6139 - val_acc: 0.6137\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.4893 - acc: 0.8691 - val_loss: 1.6445 - val_acc: 0.6643\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.3033 - acc: 0.9135 - val_loss: 0.7403 - val_acc: 0.8137\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 37s - loss: 0.1704 - acc: 0.9520 - val_loss: 0.6780 - val_acc: 0.8272\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.1090 - acc: 0.9660 - val_loss: 0.6587 - val_acc: 0.8416\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0986 - acc: 0.9738 - val_loss: 0.6221 - val_acc: 0.8518\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0734 - acc: 0.9811 - val_loss: 0.6107 - val_acc: 0.8453\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0518 - acc: 0.9862 - val_loss: 0.7484 - val_acc: 0.8435\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0644 - acc: 0.9841 - val_loss: 0.8763 - val_acc: 0.8084\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0775 - acc: 0.9804 - val_loss: 0.6377 - val_acc: 0.8604\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0403 - acc: 0.9887 - val_loss: 0.6856 - val_acc: 0.8593\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0260 - acc: 0.9947 - val_loss: 0.6844 - val_acc: 0.8480\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0120 - acc: 0.9977 - val_loss: 0.5155 - val_acc: 0.8917\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0036 - acc: 0.9993 - val_loss: 0.4616 - val_acc: 0.8963\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 36s - loss: 9.7203e-04 - acc: 0.9998 - val_loss: 0.4627 - val_acc: 0.9023\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 36s - loss: 6.5856e-04 - acc: 0.9998 - val_loss: 0.4652 - val_acc: 0.9019\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 36s - loss: 9.1219e-04 - acc: 0.9997 - val_loss: 0.4628 - val_acc: 0.9042\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 36s - loss: 6.6094e-04 - acc: 0.9997 - val_loss: 0.4669 - val_acc: 0.9068\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.0251e-04 - acc: 0.9998 - val_loss: 0.4787 - val_acc: 0.9049\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 36s - loss: 5.3020e-04 - acc: 0.9997 - val_loss: 0.4823 - val_acc: 0.9049\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.5152e-04 - acc: 0.9997 - val_loss: 0.4830 - val_acc: 0.9061\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 36s - loss: 5.3011e-04 - acc: 0.9997 - val_loss: 0.4807 - val_acc: 0.9065\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.9167e-04 - acc: 0.9997 - val_loss: 0.4848 - val_acc: 0.9053\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.7174e-04 - acc: 0.9997 - val_loss: 0.4861 - val_acc: 0.9053\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.0021e-04 - acc: 0.9998 - val_loss: 0.4927 - val_acc: 0.9046\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.0743e-04 - acc: 0.9998 - val_loss: 0.4934 - val_acc: 0.9057\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.4330e-04 - acc: 0.9997 - val_loss: 0.4984 - val_acc: 0.9053\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.8873e-04 - acc: 0.9998 - val_loss: 0.5001 - val_acc: 0.9061\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.2878e-04 - acc: 0.9997 - val_loss: 0.4991 - val_acc: 0.9049\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.2750e-04 - acc: 0.9998 - val_loss: 0.5042 - val_acc: 0.9057\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.2680e-04 - acc: 0.9998 - val_loss: 0.5077 - val_acc: 0.9049\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.9525e-04 - acc: 0.9997 - val_loss: 0.5061 - val_acc: 0.9057\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.9293e-04 - acc: 0.9997 - val_loss: 0.5069 - val_acc: 0.9061\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.8652e-04 - acc: 0.9997 - val_loss: 0.5095 - val_acc: 0.9053\n",
      "Time = 1285.1793162822723\n"
     ]
    }
   ],
   "source": [
    "###2th Experiment: trainable kernel\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#load pre-trein weights\n",
    "model.load_weights(\"D:\\\\SomeData\\\\KerasWeights\\\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")# WA for avoid directly download issue\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 15,029,157\n",
      "Trainable params: 15,029,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 37s - loss: 4.4628 - acc: 0.0870 - val_loss: 4.2481 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.2029 - acc: 0.0926 - val_loss: 4.2147 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.1910 - acc: 0.0971 - val_loss: 4.1977 - val_acc: 0.1256\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.1830 - acc: 0.0976 - val_loss: 4.1818 - val_acc: 0.0905\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.1622 - acc: 0.1045 - val_loss: 4.5971 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 36s - loss: 4.1403 - acc: 0.1118 - val_loss: 4.0836 - val_acc: 0.1064\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.9965 - acc: 0.1343 - val_loss: 3.9331 - val_acc: 0.1614\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.8228 - acc: 0.1955 - val_loss: 3.7732 - val_acc: 0.2169\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.5914 - acc: 0.2370 - val_loss: 3.9784 - val_acc: 0.1958\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.4580 - acc: 0.2717 - val_loss: 3.4982 - val_acc: 0.2882\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 36s - loss: 3.1606 - acc: 0.3241 - val_loss: 3.3289 - val_acc: 0.3172\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 36s - loss: 2.9282 - acc: 0.3641 - val_loss: 3.3347 - val_acc: 0.3180\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 36s - loss: 2.7070 - acc: 0.4028 - val_loss: 3.0805 - val_acc: 0.3297\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 36s - loss: 2.4133 - acc: 0.4564 - val_loss: 2.6855 - val_acc: 0.4191\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 36s - loss: 2.3298 - acc: 0.4685 - val_loss: 2.7231 - val_acc: 0.4164\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 36s - loss: 2.0040 - acc: 0.5325 - val_loss: 2.7475 - val_acc: 0.4259\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 36s - loss: 1.7123 - acc: 0.5855 - val_loss: 3.2488 - val_acc: 0.4029\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 36s - loss: 1.4887 - acc: 0.6250 - val_loss: 2.8744 - val_acc: 0.4070\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 36s - loss: 1.2549 - acc: 0.6854 - val_loss: 3.3878 - val_acc: 0.3682\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 36s - loss: 1.0695 - acc: 0.7164 - val_loss: 5.0173 - val_acc: 0.3508\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 36s - loss: 1.0456 - acc: 0.7449 - val_loss: 4.5560 - val_acc: 0.2848\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.8222 - acc: 0.7790 - val_loss: 3.8627 - val_acc: 0.4323\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.5888 - acc: 0.8407 - val_loss: 3.5365 - val_acc: 0.4787\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.4595 - acc: 0.8770 - val_loss: 3.9918 - val_acc: 0.4866\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.3600 - acc: 0.9024 - val_loss: 3.4112 - val_acc: 0.4881\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.2895 - acc: 0.9228 - val_loss: 5.0849 - val_acc: 0.4500\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.3134 - acc: 0.9135 - val_loss: 3.5945 - val_acc: 0.4870\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.2481 - acc: 0.9315 - val_loss: 3.8943 - val_acc: 0.4810\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.2404 - acc: 0.9368 - val_loss: 3.7714 - val_acc: 0.4911\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.1319 - acc: 0.9660 - val_loss: 4.3811 - val_acc: 0.5066\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.1355 - acc: 0.9656 - val_loss: 4.5101 - val_acc: 0.4764\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.1384 - acc: 0.9625 - val_loss: 4.3770 - val_acc: 0.4934\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.1216 - acc: 0.9708 - val_loss: 5.0204 - val_acc: 0.4994\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0747 - acc: 0.9816 - val_loss: 4.3717 - val_acc: 0.5224\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 36s - loss: 0.0661 - acc: 0.9814 - val_loss: 4.3881 - val_acc: 0.5153\n",
      "Time = 1277.0840411186218\n"
     ]
    }
   ],
   "source": [
    "###3th Experiment: just VGG16 struct (don't load pre train weights)\n",
    "\n",
    "#configure default VGG16\n",
    "model = applications.VGG16(weights=None, input_tensor = Input(shape=(128, 128, 3)), input_shape=(128, 128, 3), include_top=False)\n",
    "#configure classificator\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(goal_num_classes, activation='softmax')(x)\n",
    "my_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(my_model.summary())\n",
    "\n",
    "t0=time.time()\n",
    "my_model.fit(goal_x_train, goal_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(goal_x_test, goal_y_test),\n",
    "              shuffle=True)\n",
    "t1=time.time()\n",
    "print('Time =',(t1-t0))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
