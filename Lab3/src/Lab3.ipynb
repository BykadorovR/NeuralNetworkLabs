{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(777)\n",
    "batch_size = 32\n",
    "num_classes = 101\n",
    "epochs = 35\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ImagesPath=\"..\\\\..\\\\101_ObjectCategories\\\\\"\n",
    "classes = [f for f in listdir(ImagesPath)]\n",
    "train_volume=0.7\n",
    "size = 128,128\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "for i in range(0,len(classes)):\n",
    "    images=listdir(ImagesPath+classes[i])\n",
    "    for j in range(0,(int)(len(images)*train_volume)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        x_train.append(data)\n",
    "        y_train.append(np.uint8(i))\n",
    "    for j in range((int)(len(images)*train_volume),len(images)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        x_test.append(data)\n",
    "        y_test.append(np.uint8(i))\n",
    "x_test=np.array(x_test)\n",
    "x_train=np.array(x_train)\n",
    "\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 127008)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               65028608  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 65,090,565\n",
      "Trainable params: 65,090,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 26s - loss: 5.2772 - acc: 0.0466 - val_loss: 4.7875 - val_acc: 0.0494\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 13s - loss: 5.0696 - acc: 0.0566 - val_loss: 4.6517 - val_acc: 0.0494\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 13s - loss: 5.0771 - acc: 0.0533 - val_loss: 4.6353 - val_acc: 0.0494\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 13s - loss: 5.0225 - acc: 0.0556 - val_loss: 4.5997 - val_acc: 0.0132\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9912 - acc: 0.0581 - val_loss: 4.5716 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9901 - acc: 0.0594 - val_loss: 4.5065 - val_acc: 0.0905\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9767 - acc: 0.0519 - val_loss: 4.5010 - val_acc: 0.0905\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9579 - acc: 0.0601 - val_loss: 4.4804 - val_acc: 0.0905\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9529 - acc: 0.0594 - val_loss: 4.9879 - val_acc: 0.0905\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9619 - acc: 0.0538 - val_loss: 4.5568 - val_acc: 0.0494\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9189 - acc: 0.0582 - val_loss: 4.5577 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9050 - acc: 0.0621 - val_loss: 4.5880 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9192 - acc: 0.0632 - val_loss: 4.5816 - val_acc: 0.0272\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9050 - acc: 0.0646 - val_loss: 4.5188 - val_acc: 0.0905\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9047 - acc: 0.0586 - val_loss: 4.5913 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9270 - acc: 0.0641 - val_loss: 4.5494 - val_acc: 0.0272\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9202 - acc: 0.0632 - val_loss: 4.5706 - val_acc: 0.0102\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9244 - acc: 0.0646 - val_loss: 4.5134 - val_acc: 0.0905\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9115 - acc: 0.0626 - val_loss: 4.5532 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9019 - acc: 0.0604 - val_loss: 4.5243 - val_acc: 0.0494\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9118 - acc: 0.0574 - val_loss: 4.5363 - val_acc: 0.0905\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9088 - acc: 0.0631 - val_loss: 4.4761 - val_acc: 0.0905\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.8933 - acc: 0.0622 - val_loss: 4.5769 - val_acc: 0.0905\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9143 - acc: 0.0609 - val_loss: 4.9900 - val_acc: 0.0905\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9116 - acc: 0.0589 - val_loss: 5.0937 - val_acc: 0.0905\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.8980 - acc: 0.0614 - val_loss: 4.6189 - val_acc: 0.0905\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.8966 - acc: 0.0609 - val_loss: 4.4730 - val_acc: 0.0905\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9045 - acc: 0.0592 - val_loss: 4.9991 - val_acc: 0.0905\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9133 - acc: 0.0599 - val_loss: 4.8106 - val_acc: 0.0494\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.8977 - acc: 0.0651 - val_loss: 4.5293 - val_acc: 0.0494\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9191 - acc: 0.0611 - val_loss: 4.4500 - val_acc: 0.0905\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9209 - acc: 0.0577 - val_loss: 4.5798 - val_acc: 0.0905\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9131 - acc: 0.0617 - val_loss: 4.9224 - val_acc: 0.0905\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9095 - acc: 0.0606 - val_loss: 4.6703 - val_acc: 0.0905\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 13s - loss: 4.9040 - acc: 0.0639 - val_loss: 4.6336 - val_acc: 0.0905\n",
      "Time = 472.89614152908325\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model1.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model1.add(Activation('tanh'))\n",
    "model1.add(Conv2D(32, (3, 3)))\n",
    "model1.add(Activation('tanh'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(512))\n",
    "model1.add(Activation('tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(num_classes))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "\n",
    "plot_model(model1, to_file='model1.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 127008)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               65028608  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 65,090,565\n",
      "Trainable params: 65,090,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 13s - loss: 3.9227 - acc: 0.2078 - val_loss: 3.8284 - val_acc: 0.2652\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 13s - loss: 2.9961 - acc: 0.3679 - val_loss: 2.6229 - val_acc: 0.4270\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 13s - loss: 1.8738 - acc: 0.5667 - val_loss: 2.3420 - val_acc: 0.4791\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.8830 - acc: 0.7813 - val_loss: 2.4641 - val_acc: 0.4817\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.3030 - acc: 0.9359 - val_loss: 2.5847 - val_acc: 0.4730\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.1246 - acc: 0.9794 - val_loss: 2.5408 - val_acc: 0.4957\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0684 - acc: 0.9895 - val_loss: 2.5287 - val_acc: 0.4979\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0469 - acc: 0.9932 - val_loss: 2.5955 - val_acc: 0.4900\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0300 - acc: 0.9968 - val_loss: 2.5409 - val_acc: 0.5058\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0203 - acc: 0.9982 - val_loss: 2.5415 - val_acc: 0.5055\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0147 - acc: 0.9992 - val_loss: 2.5598 - val_acc: 0.5074\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0102 - acc: 0.9993 - val_loss: 2.6013 - val_acc: 0.5036\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0089 - acc: 0.9993 - val_loss: 2.6051 - val_acc: 0.5047\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 12s - loss: 0.0077 - acc: 0.9997 - val_loss: 2.6026 - val_acc: 0.5055\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0087 - acc: 0.9990 - val_loss: 2.5934 - val_acc: 0.5108\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0077 - acc: 0.9997 - val_loss: 2.6070 - val_acc: 0.5134\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0045 - acc: 1.0000 - val_loss: 2.6257 - val_acc: 0.5123\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0044 - acc: 0.9997 - val_loss: 2.6207 - val_acc: 0.5126\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0036 - acc: 1.0000 - val_loss: 2.6260 - val_acc: 0.5134\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0042 - acc: 0.9997 - val_loss: 2.6273 - val_acc: 0.5123\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 12s - loss: 0.0031 - acc: 0.9998 - val_loss: 2.6225 - val_acc: 0.5179\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0032 - acc: 0.9998 - val_loss: 2.6379 - val_acc: 0.5141\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0038 - acc: 0.9998 - val_loss: 2.6462 - val_acc: 0.5153\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0034 - acc: 0.9998 - val_loss: 2.6440 - val_acc: 0.5119\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0026 - acc: 0.9998 - val_loss: 2.6527 - val_acc: 0.5149\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0030 - acc: 0.9997 - val_loss: 2.6341 - val_acc: 0.5157\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0031 - acc: 0.9997 - val_loss: 2.6520 - val_acc: 0.5153\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0030 - acc: 0.9997 - val_loss: 2.6572 - val_acc: 0.5153\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0030 - acc: 0.9997 - val_loss: 2.6583 - val_acc: 0.5153\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0019 - acc: 1.0000 - val_loss: 2.6662 - val_acc: 0.5141\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0021 - acc: 0.9997 - val_loss: 2.6749 - val_acc: 0.5149\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0019 - acc: 0.9997 - val_loss: 2.6761 - val_acc: 0.5157\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0018 - acc: 0.9998 - val_loss: 2.6710 - val_acc: 0.5160\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0023 - acc: 0.9998 - val_loss: 2.6630 - val_acc: 0.5138\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0017 - acc: 1.0000 - val_loss: 2.6795 - val_acc: 0.5153\n",
      "Time = 457.8859541416168\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model2.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(512))\n",
    "model2.add(Activation('tanh'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "model2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model2, to_file='model2.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               29491712  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 29,609,093\n",
      "Trainable params: 29,609,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 14s - loss: 3.8892 - acc: 0.2068 - val_loss: 3.4242 - val_acc: 0.2799\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 13s - loss: 3.2888 - acc: 0.3125 - val_loss: 3.3039 - val_acc: 0.3357\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 13s - loss: 2.6012 - acc: 0.4358 - val_loss: 2.5030 - val_acc: 0.4459\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 13s - loss: 1.7108 - acc: 0.5898 - val_loss: 2.1666 - val_acc: 0.5164\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.8550 - acc: 0.7823 - val_loss: 2.1467 - val_acc: 0.5304\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.4080 - acc: 0.8981 - val_loss: 2.2405 - val_acc: 0.5240\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.1683 - acc: 0.9652 - val_loss: 2.2315 - val_acc: 0.5394\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0939 - acc: 0.9836 - val_loss: 2.2441 - val_acc: 0.5383\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0529 - acc: 0.9927 - val_loss: 2.2456 - val_acc: 0.5424\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0358 - acc: 0.9957 - val_loss: 2.2363 - val_acc: 0.5432\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0294 - acc: 0.9965 - val_loss: 2.2481 - val_acc: 0.5473\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0247 - acc: 0.9968 - val_loss: 2.2298 - val_acc: 0.5504\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0195 - acc: 0.9985 - val_loss: 2.2632 - val_acc: 0.5485\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0143 - acc: 0.9985 - val_loss: 2.2482 - val_acc: 0.5575\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0132 - acc: 0.9982 - val_loss: 2.2557 - val_acc: 0.5560\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0120 - acc: 0.9985 - val_loss: 2.2649 - val_acc: 0.5541\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0090 - acc: 0.9993 - val_loss: 2.2583 - val_acc: 0.5526\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0068 - acc: 0.9997 - val_loss: 2.2415 - val_acc: 0.5575\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0065 - acc: 0.9995 - val_loss: 2.2634 - val_acc: 0.5613\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0078 - acc: 0.9988 - val_loss: 2.2819 - val_acc: 0.5538\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0077 - acc: 0.9997 - val_loss: 2.2732 - val_acc: 0.5545\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0059 - acc: 0.9995 - val_loss: 2.2840 - val_acc: 0.5534\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0077 - acc: 0.9988 - val_loss: 2.2494 - val_acc: 0.5579\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0060 - acc: 0.9997 - val_loss: 2.2776 - val_acc: 0.5534\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0046 - acc: 0.9997 - val_loss: 2.3006 - val_acc: 0.5534\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0050 - acc: 0.9995 - val_loss: 2.2993 - val_acc: 0.5575\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0042 - acc: 0.9995 - val_loss: 2.2989 - val_acc: 0.5575\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0043 - acc: 0.9997 - val_loss: 2.2867 - val_acc: 0.5605\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0031 - acc: 1.0000 - val_loss: 2.2755 - val_acc: 0.5617\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0033 - acc: 0.9997 - val_loss: 2.2769 - val_acc: 0.5628\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0025 - acc: 1.0000 - val_loss: 2.3062 - val_acc: 0.5602\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0045 - acc: 0.9997 - val_loss: 2.3031 - val_acc: 0.5605\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0030 - acc: 0.9997 - val_loss: 2.2919 - val_acc: 0.5624\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0027 - acc: 0.9998 - val_loss: 2.2832 - val_acc: 0.5647\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0053 - acc: 0.9995 - val_loss: 2.3188 - val_acc: 0.5598\n",
      "Time = 472.6186282634735\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model3.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(32, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.25))\n",
    "\n",
    "model3.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.25))\n",
    "\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(512))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(num_classes))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model3.summary())\n",
    "\n",
    "model3.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model3, to_file='model3.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               29491712  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 29,609,093\n",
      "Trainable params: 29,609,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 14s - loss: 3.6765 - acc: 0.2514 - val_loss: 2.9742 - val_acc: 0.3806\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 13s - loss: 2.4128 - acc: 0.4686 - val_loss: 2.3107 - val_acc: 0.4915\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 13s - loss: 1.3659 - acc: 0.6643 - val_loss: 2.0183 - val_acc: 0.5398\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.5734 - acc: 0.8558 - val_loss: 1.9784 - val_acc: 0.5681\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.2026 - acc: 0.9575 - val_loss: 1.9041 - val_acc: 0.5839\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0832 - acc: 0.9852 - val_loss: 1.9199 - val_acc: 0.5903\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0414 - acc: 0.9949 - val_loss: 1.9151 - val_acc: 0.5930\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0235 - acc: 0.9978 - val_loss: 1.9024 - val_acc: 0.5949\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0158 - acc: 0.9987 - val_loss: 1.9018 - val_acc: 0.6020\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0134 - acc: 0.9992 - val_loss: 1.9137 - val_acc: 0.6043\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0082 - acc: 0.9998 - val_loss: 1.9081 - val_acc: 0.6047\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0081 - acc: 0.9990 - val_loss: 1.9302 - val_acc: 0.6002\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0078 - acc: 0.9997 - val_loss: 1.9095 - val_acc: 0.6084\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0065 - acc: 0.9992 - val_loss: 1.9166 - val_acc: 0.6054\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0053 - acc: 0.9997 - val_loss: 1.9285 - val_acc: 0.6039\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0038 - acc: 1.0000 - val_loss: 1.9210 - val_acc: 0.6058\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0057 - acc: 0.9997 - val_loss: 1.9200 - val_acc: 0.6096\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0040 - acc: 0.9997 - val_loss: 1.9362 - val_acc: 0.6058\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0033 - acc: 0.9997 - val_loss: 1.9188 - val_acc: 0.6084\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0036 - acc: 0.9998 - val_loss: 1.9377 - val_acc: 0.6073\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0031 - acc: 0.9998 - val_loss: 1.9274 - val_acc: 0.6054\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0026 - acc: 0.9998 - val_loss: 1.9235 - val_acc: 0.6096\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0023 - acc: 1.0000 - val_loss: 1.9335 - val_acc: 0.6092\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0024 - acc: 0.9997 - val_loss: 1.9338 - val_acc: 0.6096\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0023 - acc: 0.9998 - val_loss: 1.9284 - val_acc: 0.6100\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0028 - acc: 0.9997 - val_loss: 1.9376 - val_acc: 0.6088\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0021 - acc: 0.9998 - val_loss: 1.9231 - val_acc: 0.6103\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0019 - acc: 0.9998 - val_loss: 1.9295 - val_acc: 0.6100\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0017 - acc: 1.0000 - val_loss: 1.9439 - val_acc: 0.6096\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0019 - acc: 0.9998 - val_loss: 1.9324 - val_acc: 0.6137\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0021 - acc: 0.9997 - val_loss: 1.9443 - val_acc: 0.6115\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0020 - acc: 0.9998 - val_loss: 1.9445 - val_acc: 0.6088\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0019 - acc: 0.9997 - val_loss: 1.9434 - val_acc: 0.6156\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0022 - acc: 0.9998 - val_loss: 1.9604 - val_acc: 0.6100\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0014 - acc: 1.0000 - val_loss: 1.9521 - val_acc: 0.6134\n",
      "Time = 474.99136567115784\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model4.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model4.add(Activation('tanh'))\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(Activation('tanh'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "model4.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Conv2D(64, (3, 3)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(512))\n",
    "model4.add(Activation('tanh'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(num_classes))\n",
    "model4.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model4.summary())\n",
    "\n",
    "model4.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model4, to_file='model4.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               29491712  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 29,609,093\n",
      "Trainable params: 29,609,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 13s - loss: 3.6517 - acc: 0.2529 - val_loss: 2.7726 - val_acc: 0.4108\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 13s - loss: 2.2894 - acc: 0.4849 - val_loss: 2.4490 - val_acc: 0.4685\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 13s - loss: 1.1551 - acc: 0.7139 - val_loss: 2.4697 - val_acc: 0.4760\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.4940 - acc: 0.8799 - val_loss: 2.5512 - val_acc: 0.4727\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.2279 - acc: 0.9494 - val_loss: 2.5200 - val_acc: 0.4938\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.1111 - acc: 0.9778 - val_loss: 2.5929 - val_acc: 0.4862\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0695 - acc: 0.9889 - val_loss: 2.5837 - val_acc: 0.4911\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0404 - acc: 0.9955 - val_loss: 2.5750 - val_acc: 0.4983\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0269 - acc: 0.9977 - val_loss: 2.5530 - val_acc: 0.5058\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0243 - acc: 0.9970 - val_loss: 2.5357 - val_acc: 0.5100\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0182 - acc: 0.9987 - val_loss: 2.5528 - val_acc: 0.5119\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0126 - acc: 0.9992 - val_loss: 2.5771 - val_acc: 0.5126\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0119 - acc: 0.9992 - val_loss: 2.5486 - val_acc: 0.5115\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0114 - acc: 0.9995 - val_loss: 2.5459 - val_acc: 0.5111\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0096 - acc: 0.9992 - val_loss: 2.5448 - val_acc: 0.5149\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0084 - acc: 0.9993 - val_loss: 2.5565 - val_acc: 0.5134\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0077 - acc: 0.9997 - val_loss: 2.5486 - val_acc: 0.5194\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0061 - acc: 0.9997 - val_loss: 2.5284 - val_acc: 0.5175\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0060 - acc: 0.9998 - val_loss: 2.5477 - val_acc: 0.5221\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0059 - acc: 0.9995 - val_loss: 2.5390 - val_acc: 0.5183\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0045 - acc: 0.9997 - val_loss: 2.5676 - val_acc: 0.5149\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0049 - acc: 0.9997 - val_loss: 2.5528 - val_acc: 0.5145\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0038 - acc: 0.9998 - val_loss: 2.5616 - val_acc: 0.5115\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0041 - acc: 0.9998 - val_loss: 2.5752 - val_acc: 0.5111\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0038 - acc: 0.9997 - val_loss: 2.5731 - val_acc: 0.5111\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0042 - acc: 0.9997 - val_loss: 2.5617 - val_acc: 0.5175\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0044 - acc: 0.9998 - val_loss: 2.5826 - val_acc: 0.5168\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0039 - acc: 0.9995 - val_loss: 2.5787 - val_acc: 0.5168\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0038 - acc: 0.9997 - val_loss: 2.5602 - val_acc: 0.5187\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0035 - acc: 0.9997 - val_loss: 2.5526 - val_acc: 0.5168\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0037 - acc: 0.9997 - val_loss: 2.5705 - val_acc: 0.5126\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0024 - acc: 1.0000 - val_loss: 2.5681 - val_acc: 0.5138\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0027 - acc: 0.9995 - val_loss: 2.5697 - val_acc: 0.5164\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0023 - acc: 0.9997 - val_loss: 2.5692 - val_acc: 0.5172\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 13s - loss: 0.0041 - acc: 0.9997 - val_loss: 2.5631 - val_acc: 0.5202\n",
      "Time = 458.7914171218872\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model5.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Conv2D(32, (3, 3)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model5.add(Activation('linear'))\n",
    "model5.add(Conv2D(64, (3, 3)))\n",
    "model5.add(Activation('linear'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(512))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(num_classes))\n",
    "model5.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model5.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model5.summary())\n",
    "\n",
    "model5.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model5, to_file='model5.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.9077 - acc: 0.1935 - val_loss: 3.4075 - val_acc: 0.3176\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.0073 - acc: 0.3699 - val_loss: 2.9840 - val_acc: 0.3546\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 15s - loss: 2.4193 - acc: 0.4628 - val_loss: 2.5358 - val_acc: 0.4523\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.8659 - acc: 0.5597 - val_loss: 2.2757 - val_acc: 0.4900\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.3886 - acc: 0.6591 - val_loss: 2.3513 - val_acc: 0.4847\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.9497 - acc: 0.7519 - val_loss: 1.9999 - val_acc: 0.5632\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.6562 - acc: 0.8259 - val_loss: 1.9420 - val_acc: 0.5779\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.4289 - acc: 0.8845 - val_loss: 1.9642 - val_acc: 0.5775\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.2622 - acc: 0.9333 - val_loss: 2.0147 - val_acc: 0.5805\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.1848 - acc: 0.9569 - val_loss: 1.9544 - val_acc: 0.5949\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.1235 - acc: 0.9716 - val_loss: 1.9795 - val_acc: 0.6020\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0855 - acc: 0.9844 - val_loss: 1.9652 - val_acc: 0.6092\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0615 - acc: 0.9894 - val_loss: 1.9614 - val_acc: 0.6100\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0506 - acc: 0.9915 - val_loss: 1.9781 - val_acc: 0.5983\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0431 - acc: 0.9929 - val_loss: 1.9708 - val_acc: 0.6035\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0381 - acc: 0.9939 - val_loss: 1.9836 - val_acc: 0.6122\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0309 - acc: 0.9967 - val_loss: 1.9678 - val_acc: 0.6069\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0281 - acc: 0.9960 - val_loss: 1.9691 - val_acc: 0.6115\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0248 - acc: 0.9959 - val_loss: 1.9953 - val_acc: 0.6103\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0217 - acc: 0.9977 - val_loss: 1.9672 - val_acc: 0.6217\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0186 - acc: 0.9987 - val_loss: 1.9906 - val_acc: 0.6115\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0161 - acc: 0.9978 - val_loss: 1.9580 - val_acc: 0.6164\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0154 - acc: 0.9982 - val_loss: 1.9823 - val_acc: 0.6141\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0128 - acc: 0.9988 - val_loss: 1.9995 - val_acc: 0.6152\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0121 - acc: 0.9988 - val_loss: 1.9977 - val_acc: 0.6092\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0114 - acc: 0.9988 - val_loss: 2.0105 - val_acc: 0.6164\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0102 - acc: 0.9987 - val_loss: 2.0072 - val_acc: 0.6164\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0114 - acc: 0.9990 - val_loss: 2.0140 - val_acc: 0.6160\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0095 - acc: 0.9993 - val_loss: 1.9943 - val_acc: 0.6171\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0084 - acc: 0.9992 - val_loss: 1.9987 - val_acc: 0.6190\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0084 - acc: 0.9988 - val_loss: 2.0298 - val_acc: 0.6111\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0066 - acc: 0.9995 - val_loss: 1.9758 - val_acc: 0.6205\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0077 - acc: 0.9992 - val_loss: 1.9938 - val_acc: 0.6160\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0064 - acc: 0.9990 - val_loss: 1.9961 - val_acc: 0.6145\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0062 - acc: 0.9993 - val_loss: 2.0015 - val_acc: 0.6198\n",
      "Time = 533.6936407089233\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model6.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Conv2D(32, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Dropout(0.25))\n",
    "\n",
    "model6.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Conv2D(64, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Dropout(0.25))\n",
    "\n",
    "model6.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model6.add(Activation('tanh'))\n",
    "model6.add(Conv2D(128, (5, 5)))\n",
    "model6.add(Activation('tanh'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Dropout(0.25))\n",
    "\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(512))\n",
    "model6.add(Activation('tanh'))\n",
    "model6.add(Dropout(0.5))\n",
    "model6.add(Dense(num_classes))\n",
    "model6.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model6.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model6.summary())\n",
    "\n",
    "model6.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model6, to_file='model6.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.3796 - acc: 0.0896 - val_loss: 4.2376 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2532 - acc: 0.0938 - val_loss: 4.3844 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2469 - acc: 0.0853 - val_loss: 4.2474 - val_acc: 0.0905\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2459 - acc: 0.0918 - val_loss: 4.2385 - val_acc: 0.0905\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2399 - acc: 0.0893 - val_loss: 4.2238 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2367 - acc: 0.0929 - val_loss: 4.2260 - val_acc: 0.0905\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2358 - acc: 0.0903 - val_loss: 4.2405 - val_acc: 0.0905\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2267 - acc: 0.0929 - val_loss: 4.2234 - val_acc: 0.0905\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2223 - acc: 0.0948 - val_loss: 4.2307 - val_acc: 0.0905\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2213 - acc: 0.0928 - val_loss: 4.2160 - val_acc: 0.0905\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2220 - acc: 0.0926 - val_loss: 4.2207 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2252 - acc: 0.0866 - val_loss: 4.2184 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2219 - acc: 0.0885 - val_loss: 4.2203 - val_acc: 0.0905\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2252 - acc: 0.0953 - val_loss: 4.2145 - val_acc: 0.0905\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2203 - acc: 0.0923 - val_loss: 4.2151 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2256 - acc: 0.0972 - val_loss: 4.2243 - val_acc: 0.0905\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2251 - acc: 0.0916 - val_loss: 4.2158 - val_acc: 0.0905\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2229 - acc: 0.0976 - val_loss: 4.2348 - val_acc: 0.0905\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2245 - acc: 0.0911 - val_loss: 4.2393 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2237 - acc: 0.0899 - val_loss: 4.2155 - val_acc: 0.0905\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2185 - acc: 0.0899 - val_loss: 4.2185 - val_acc: 0.0905\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2265 - acc: 0.0851 - val_loss: 4.2284 - val_acc: 0.0905\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2223 - acc: 0.0959 - val_loss: 4.2293 - val_acc: 0.0905\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2210 - acc: 0.0929 - val_loss: 4.2198 - val_acc: 0.0905\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2238 - acc: 0.0949 - val_loss: 4.2277 - val_acc: 0.0905\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2209 - acc: 0.0931 - val_loss: 4.2178 - val_acc: 0.0905 ETA: 1s - loss\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2221 - acc: 0.0876 - val_loss: 4.2156 - val_acc: 0.0905\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2181 - acc: 0.0931 - val_loss: 4.2204 - val_acc: 0.0905\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2225 - acc: 0.0958 - val_loss: 4.2161 - val_acc: 0.0905\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2187 - acc: 0.0919 - val_loss: 4.2240 - val_acc: 0.0905\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2188 - acc: 0.0914 - val_loss: 4.2203 - val_acc: 0.0905\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2226 - acc: 0.0949 - val_loss: 4.2275 - val_acc: 0.0905\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2183 - acc: 0.0949 - val_loss: 4.2345 - val_acc: 0.0905\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2230 - acc: 0.0914 - val_loss: 4.2124 - val_acc: 0.0905\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.2170 - acc: 0.0941 - val_loss: 4.2205 - val_acc: 0.0905\n",
      "Time = 529.4811840057373\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model7.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model7.add(Activation('sigmoid'))\n",
    "model7.add(Conv2D(32, (3, 3)))\n",
    "model7.add(Activation('sigmoid'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Dropout(0.25))\n",
    "\n",
    "model7.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model7.add(Activation('relu'))\n",
    "model7.add(Conv2D(64, (3, 3)))\n",
    "model7.add(Activation('relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Dropout(0.25))\n",
    "\n",
    "model7.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model7.add(Activation('tanh'))\n",
    "model7.add(Conv2D(128, (5, 5)))\n",
    "model7.add(Activation('tanh'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Dropout(0.25))\n",
    "\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(512))\n",
    "model7.add(Activation('tanh'))\n",
    "model7.add(Dropout(0.5))\n",
    "model7.add(Dense(num_classes))\n",
    "model7.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model7.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model7.summary())\n",
    "\n",
    "model7.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model7, to_file='model7.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.2228 - acc: 0.0518 - val_loss: 4.5423 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.1202 - acc: 0.0568 - val_loss: 4.6354 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0736 - acc: 0.0533 - val_loss: 5.0035 - val_acc: 0.0905\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0231 - acc: 0.0614 - val_loss: 4.5642 - val_acc: 0.0272\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9970 - acc: 0.0594 - val_loss: 4.6535 - val_acc: 0.0494\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9941 - acc: 0.0577 - val_loss: 4.6497 - val_acc: 0.0494\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9625 - acc: 0.0592 - val_loss: 4.6461 - val_acc: 0.0905\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9631 - acc: 0.0597 - val_loss: 4.5536 - val_acc: 0.0905\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9436 - acc: 0.0551 - val_loss: 4.4913 - val_acc: 0.0494\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9447 - acc: 0.0607 - val_loss: 4.4178 - val_acc: 0.0905\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9006 - acc: 0.0637 - val_loss: 4.4702 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9357 - acc: 0.0582 - val_loss: 4.5429 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9293 - acc: 0.0601 - val_loss: 4.4940 - val_acc: 0.0905\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9211 - acc: 0.0586 - val_loss: 4.7028 - val_acc: 0.0905\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9178 - acc: 0.0609 - val_loss: 4.5603 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9190 - acc: 0.0581 - val_loss: 4.5229 - val_acc: 0.0905\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9241 - acc: 0.0649 - val_loss: 5.2063 - val_acc: 0.0905\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9027 - acc: 0.0556 - val_loss: 4.8180 - val_acc: 0.0494\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9153 - acc: 0.0601 - val_loss: 4.9466 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9210 - acc: 0.0582 - val_loss: 4.5012 - val_acc: 0.0494\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9368 - acc: 0.0581 - val_loss: 4.6710 - val_acc: 0.0494\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9240 - acc: 0.0551 - val_loss: 4.5431 - val_acc: 0.0905\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9222 - acc: 0.0616 - val_loss: 4.5507 - val_acc: 0.0905\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8910 - acc: 0.0641 - val_loss: 4.6574 - val_acc: 0.0905\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9345 - acc: 0.0576 - val_loss: 4.7345 - val_acc: 0.0905\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8950 - acc: 0.0624 - val_loss: 4.5275 - val_acc: 0.0494\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9198 - acc: 0.0563 - val_loss: 4.4983 - val_acc: 0.0905\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9111 - acc: 0.0602 - val_loss: 4.4309 - val_acc: 0.0905\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9349 - acc: 0.0551 - val_loss: 4.7348 - val_acc: 0.0272.0\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9452 - acc: 0.0604 - val_loss: 4.5807 - val_acc: 0.0226\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8992 - acc: 0.0654 - val_loss: 4.7051 - val_acc: 0.0494\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9185 - acc: 0.0594 - val_loss: 4.6499 - val_acc: 0.0905\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8946 - acc: 0.0622 - val_loss: 4.5116 - val_acc: 0.0905\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9193 - acc: 0.0619 - val_loss: 4.5219 - val_acc: 0.0494\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8977 - acc: 0.0604 - val_loss: 4.5726 - val_acc: 0.0905\n",
      "Time = 533.0725204944611\n"
     ]
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model8.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model8.add(Activation('relu'))\n",
    "model8.add(Conv2D(32, (3, 3)))\n",
    "model8.add(Activation('relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(0.25))\n",
    "\n",
    "model8.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model8.add(Activation('sigmoid'))\n",
    "model8.add(Conv2D(64, (3, 3)))\n",
    "model8.add(Activation('sigmoid'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(0.25))\n",
    "\n",
    "model8.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model8.add(Activation('tanh'))\n",
    "model8.add(Conv2D(128, (5, 5)))\n",
    "model8.add(Activation('tanh'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(0.25))\n",
    "\n",
    "model8.add(Flatten())\n",
    "model8.add(Dense(512))\n",
    "model8.add(Activation('tanh'))\n",
    "model8.add(Dropout(0.5))\n",
    "model8.add(Dense(num_classes))\n",
    "model8.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model8.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model8.summary())\n",
    "\n",
    "model8.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model8, to_file='model8.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.0338 - acc: 0.1635 - val_loss: 3.3408 - val_acc: 0.3067\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 3.0110 - acc: 0.3747 - val_loss: 2.6536 - val_acc: 0.4353\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 15s - loss: 2.2842 - acc: 0.4819 - val_loss: 2.6658 - val_acc: 0.4312\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.7463 - acc: 0.5836 - val_loss: 2.2797 - val_acc: 0.4972\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 15s - loss: 1.2783 - acc: 0.6728 - val_loss: 2.1415 - val_acc: 0.5145\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.8990 - acc: 0.7605 - val_loss: 2.2745 - val_acc: 0.5130\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.6305 - acc: 0.8258 - val_loss: 2.1635 - val_acc: 0.5447\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.4570 - acc: 0.8724 - val_loss: 2.2369 - val_acc: 0.5273\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.3142 - acc: 0.9137 - val_loss: 2.2784 - val_acc: 0.5406\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.2366 - acc: 0.9371 - val_loss: 2.2890 - val_acc: 0.5387\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.1626 - acc: 0.9583 - val_loss: 2.2853 - val_acc: 0.5511\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.1492 - acc: 0.9637 - val_loss: 2.3551 - val_acc: 0.5402\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0979 - acc: 0.9773 - val_loss: 2.2684 - val_acc: 0.5651\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0934 - acc: 0.9769 - val_loss: 2.3408 - val_acc: 0.5613\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0755 - acc: 0.9842 - val_loss: 2.3505 - val_acc: 0.5538\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0592 - acc: 0.9867 - val_loss: 2.3047 - val_acc: 0.5636\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0507 - acc: 0.9899 - val_loss: 2.3998 - val_acc: 0.5549\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0390 - acc: 0.9947 - val_loss: 2.3318 - val_acc: 0.5617\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0334 - acc: 0.9937 - val_loss: 2.3464 - val_acc: 0.5673\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0311 - acc: 0.9935 - val_loss: 2.3684 - val_acc: 0.5700\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0315 - acc: 0.9945 - val_loss: 2.3980 - val_acc: 0.5654\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0240 - acc: 0.9957 - val_loss: 2.3421 - val_acc: 0.5745\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0279 - acc: 0.9942 - val_loss: 2.4225 - val_acc: 0.5628\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0305 - acc: 0.9935 - val_loss: 2.3836 - val_acc: 0.5786\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0264 - acc: 0.9949 - val_loss: 2.3834 - val_acc: 0.5711\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0244 - acc: 0.9949 - val_loss: 2.4304 - val_acc: 0.5647\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0210 - acc: 0.9952 - val_loss: 2.4170 - val_acc: 0.5654\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0147 - acc: 0.9978 - val_loss: 2.4044 - val_acc: 0.5688\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0163 - acc: 0.9970 - val_loss: 2.3958 - val_acc: 0.5734\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0161 - acc: 0.9965 - val_loss: 2.4114 - val_acc: 0.5692\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0121 - acc: 0.9985 - val_loss: 2.3915 - val_acc: 0.5764\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0116 - acc: 0.9987 - val_loss: 2.3858 - val_acc: 0.5783\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0147 - acc: 0.9973 - val_loss: 2.4228 - val_acc: 0.5764\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0134 - acc: 0.9982 - val_loss: 2.4130 - val_acc: 0.5790\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 0.0112 - acc: 0.9982 - val_loss: 2.4259 - val_acc: 0.5760\n",
      "Time = 529.6571869850159\n"
     ]
    }
   ],
   "source": [
    "model9 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model9.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model9.add(Activation('relu'))\n",
    "model9.add(Conv2D(32, (3, 3)))\n",
    "model9.add(Activation('relu'))\n",
    "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(0.25))\n",
    "\n",
    "model9.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model9.add(Activation('relu'))\n",
    "model9.add(Conv2D(64, (3, 3)))\n",
    "model9.add(Activation('relu'))\n",
    "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(0.25))\n",
    "\n",
    "model9.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model9.add(Activation('relu'))\n",
    "model9.add(Conv2D(128, (5, 5)))\n",
    "model9.add(Activation('relu'))\n",
    "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(0.25))\n",
    "\n",
    "model9.add(Flatten())\n",
    "model9.add(Dense(512))\n",
    "model9.add(Activation('tanh'))\n",
    "model9.add(Dropout(0.5))\n",
    "model9.add(Dense(num_classes))\n",
    "model9.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model9.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model9.summary())\n",
    "\n",
    "model9.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model9, to_file='model9.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.7073 - acc: 0.0486 - val_loss: 5.2433 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.1554 - acc: 0.0529 - val_loss: 4.5721 - val_acc: 0.0057\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0669 - acc: 0.0475 - val_loss: 4.5332 - val_acc: 0.0905\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0106 - acc: 0.0538 - val_loss: 5.0935 - val_acc: 0.0905\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 15s - loss: 5.0190 - acc: 0.0539 - val_loss: 4.7521 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9796 - acc: 0.0612 - val_loss: 4.8112 - val_acc: 0.0905\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9943 - acc: 0.0563 - val_loss: 4.5056 - val_acc: 0.0905\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9587 - acc: 0.0541 - val_loss: 4.4970 - val_acc: 0.0905\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9584 - acc: 0.0582 - val_loss: 4.6182 - val_acc: 0.0905\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9067 - acc: 0.0634 - val_loss: 4.7524 - val_acc: 0.0905\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9363 - acc: 0.0582 - val_loss: 4.5366 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9280 - acc: 0.0594 - val_loss: 4.4963 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9105 - acc: 0.0621 - val_loss: 4.5080 - val_acc: 0.0905\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9170 - acc: 0.0587 - val_loss: 4.5643 - val_acc: 0.0494 \n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9163 - acc: 0.0636 - val_loss: 4.7475 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9253 - acc: 0.0579 - val_loss: 4.6531 - val_acc: 0.0905\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9368 - acc: 0.0558 - val_loss: 4.5259 - val_acc: 0.0091\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9367 - acc: 0.0587 - val_loss: 4.4535 - val_acc: 0.0905\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9271 - acc: 0.0594 - val_loss: 4.5751 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9163 - acc: 0.0604 - val_loss: 4.5566 - val_acc: 0.0905\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8985 - acc: 0.0558 - val_loss: 4.7245 - val_acc: 0.0905\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8797 - acc: 0.0611 - val_loss: 4.4975 - val_acc: 0.0905\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9305 - acc: 0.0637 - val_loss: 4.6486 - val_acc: 0.0147\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9422 - acc: 0.0599 - val_loss: 4.5762 - val_acc: 0.0494\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9108 - acc: 0.0624 - val_loss: 4.5591 - val_acc: 0.0905\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.8862 - acc: 0.0672 - val_loss: 4.5904 - val_acc: 0.0905\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9234 - acc: 0.0589 - val_loss: 4.5131 - val_acc: 0.0494\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9103 - acc: 0.0591 - val_loss: 4.6629 - val_acc: 0.0226\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9178 - acc: 0.0602 - val_loss: 4.4501 - val_acc: 0.0905\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9060 - acc: 0.0619 - val_loss: 4.6032 - val_acc: 0.0494\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9166 - acc: 0.0602 - val_loss: 4.4757 - val_acc: 0.0905\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9029 - acc: 0.0652 - val_loss: 4.5049 - val_acc: 0.0905\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9237 - acc: 0.0670 - val_loss: 4.5791 - val_acc: 0.0905\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9086 - acc: 0.0621 - val_loss: 5.0526 - val_acc: 0.0905\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 15s - loss: 4.9198 - acc: 0.0617 - val_loss: 4.4631 - val_acc: 0.0905\n",
      "Time = 535.4328231811523\n"
     ]
    }
   ],
   "source": [
    "model10 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model10.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model10.add(Activation('tanh'))\n",
    "model10.add(Conv2D(32, (3, 3)))\n",
    "model10.add(Activation('tanh'))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(0.25))\n",
    "\n",
    "model10.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model10.add(Activation('tanh'))\n",
    "model10.add(Conv2D(64, (3, 3)))\n",
    "model10.add(Activation('tanh'))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(0.25))\n",
    "\n",
    "model10.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model10.add(Activation('tanh'))\n",
    "model10.add(Conv2D(128, (5, 5)))\n",
    "model10.add(Activation('tanh'))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(0.25))\n",
    "\n",
    "model10.add(Flatten())\n",
    "model10.add(Dense(512))\n",
    "model10.add(Activation('tanh'))\n",
    "model10.add(Dropout(0.5))\n",
    "model10.add(Dense(num_classes))\n",
    "model10.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model10.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model10.summary())\n",
    "\n",
    "model10.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "plot_model(model10, to_file='model10.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
